{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Es_QqtcW1P-Q",
        "outputId": "e385303a-7b5b-46d3-9c18-5176a71f68f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Perceptron for NAND Gate\n",
            "NAND Accuracy: 100.00%\n",
            "Predictions: [1, 1, 1, 0]\n",
            "\n",
            "Training Perceptron for XOR Gate\n",
            "XOR Accuracy: 50.00%\n",
            "Predictions: [1, 1, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, input_size, learning_rate=0.1, epochs=100):\n",
        "        self.weights = np.random.randn(input_size + 1)  # Including bias\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "\n",
        "    def activation(self, x):\n",
        "        return 1 if x >= 0 else 0\n",
        "\n",
        "    def predict(self, x):\n",
        "        x = np.insert(x, 0, 1)  # Adding bias term\n",
        "        return self.activation(np.dot(self.weights, x))\n",
        "\n",
        "    def train(self, X, y):\n",
        "        for _ in range(self.epochs):\n",
        "            for inputs, target in zip(X, y):\n",
        "                prediction = self.predict(inputs)\n",
        "                error = target - prediction\n",
        "                self.weights += self.learning_rate * error * np.insert(inputs, 0, 1)  # Update weights\n",
        "\n",
        "    def evaluate(self, X, y):\n",
        "        predictions = [self.predict(x) for x in X]\n",
        "        accuracy = sum(np.array(predictions) == np.array(y)) / len(y)\n",
        "        return accuracy, predictions\n",
        "\n",
        "# NAND truth table\n",
        "X_nand = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y_nand = np.array([1, 1, 1, 0])  # NAND output\n",
        "\n",
        "# Train Perceptron for NAND\n",
        "print(\"Training Perceptron for NAND Gate\")\n",
        "nand_perceptron = Perceptron(input_size=2)\n",
        "nand_perceptron.train(X_nand, y_nand)\n",
        "nand_accuracy, nand_predictions = nand_perceptron.evaluate(X_nand, y_nand)\n",
        "print(f\"NAND Accuracy: {nand_accuracy * 100:.2f}%\")\n",
        "print(\"Predictions:\", nand_predictions)\n",
        "\n",
        "# XOR truth table\n",
        "X_xor = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y_xor = np.array([0, 1, 1, 0])  # XOR output\n",
        "\n",
        "# Train Perceptron for XOR\n",
        "print(\"\\nTraining Perceptron for XOR Gate\")\n",
        "xor_perceptron = Perceptron(input_size=2)\n",
        "xor_perceptron.train(X_xor, y_xor)\n",
        "xor_accuracy, xor_predictions = xor_perceptron.evaluate(X_xor, y_xor)\n",
        "print(f\"XOR Accuracy: {xor_accuracy * 100:.2f}%\")\n",
        "print(\"Predictions:\", xor_predictions)\n",
        "\n",
        "# Expected Results:\n",
        "# - NAND gate should be learned correctly since it is linearly separable.\n",
        "# - XOR gate should not be learned correctly since it is not linearly separable with a single perceptron.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b4RxKc791vRu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}